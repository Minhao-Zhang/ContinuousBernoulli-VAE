{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as tdist\n",
    "\n",
    "MODEL_PATH = '../trained_models'\n",
    "FIG_PATH = '../figs'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models\n",
    "\n",
    "class VAE2(nn.Module):\n",
    "    def __init__(self, hidden_dims=[500, 500, 2, 500, 500], data_dim=784):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.device = device\n",
    "        # define IO\n",
    "        self.in_layer = nn.Linear(data_dim, hidden_dims[0])\n",
    "        self.out_layer = nn.Linear(hidden_dims[-1], data_dim)\n",
    "        # hidden layer\n",
    "        self.enc_h = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        # define hidden and latent\n",
    "        self.enc_mu = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.enc_sigma = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        # hidden layer decoder\n",
    "        self.dec_h = nn.Linear(hidden_dims[2], hidden_dims[-2])\n",
    "        self.dec_layer = nn.Linear(hidden_dims[-2], hidden_dims[-1])\n",
    "        self.to(device)\n",
    "\n",
    "    def encode(self, x: torch.Tensor):\n",
    "        h1 = F.dropout(F.relu(self.in_layer(x)), p=0.1)\n",
    "        h2 = F.dropout(F.relu(self.enc_h(h1)), p=0.1)\n",
    "        return self.enc_mu(h2), self.enc_sigma(h2)\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h3 = F.dropout(F.relu(self.dec_h(z)), p=0.1)\n",
    "        h4 = F.dropout(F.relu(self.dec_layer(h3)), p=0.1)\n",
    "        return torch.sigmoid(self.out_layer(h4))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mu, logvar = self.encode(x.view(-1, self.data_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "class VAE20(nn.Module):\n",
    "    def __init__(self, hidden_dims=[500, 500, 20, 500, 500], data_dim=784):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.device = device\n",
    "        # define IO\n",
    "        self.in_layer = nn.Linear(data_dim, hidden_dims[0])\n",
    "        self.out_layer = nn.Linear(hidden_dims[-1], data_dim)\n",
    "        # hidden layer\n",
    "        self.enc_h = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        # define hidden and latent\n",
    "        self.enc_mu = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.enc_sigma = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        # hidden layer decoder\n",
    "        self.dec_h = nn.Linear(hidden_dims[2], hidden_dims[-2])\n",
    "        self.dec_layer = nn.Linear(hidden_dims[-2], hidden_dims[-1])\n",
    "        self.to(device)\n",
    "\n",
    "    def encode(self, x: torch.Tensor):\n",
    "        h1 = F.dropout(F.relu(self.in_layer(x)), p=0.1)\n",
    "        h2 = F.dropout(F.relu(self.enc_h(h1)), p=0.1)\n",
    "        return self.enc_mu(h2), self.enc_sigma(h2)\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h3 = F.dropout(F.relu(self.dec_h(z)), p=0.1)\n",
    "        h4 = F.dropout(F.relu(self.dec_layer(h3)), p=0.1)\n",
    "        return torch.sigmoid(self.out_layer(h4))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mu, logvar = self.encode(x.view(-1, self.data_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "class CBVAE(nn.Module):\n",
    "    def __init__(self, hidden_dims=[500, 500, 20, 500, 500], data_dim=784):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.device = device\n",
    "        # define IO\n",
    "        self.in_layer = nn.Linear(data_dim, hidden_dims[0])\n",
    "        self.out_layer = nn.Linear(hidden_dims[-1], data_dim)\n",
    "        # hidden layer\n",
    "        self.enc_h = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        # define hidden and latent\n",
    "        self.enc_mu = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.enc_sigma = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        # hidden layer decoder\n",
    "        self.dec_h = nn.Linear(hidden_dims[2], hidden_dims[-2])\n",
    "        self.dec_layer = nn.Linear(hidden_dims[-2], hidden_dims[-1])\n",
    "        self.to(device)\n",
    "\n",
    "    def encode(self, x: torch.Tensor):\n",
    "        h1 = F.dropout(F.relu(self.in_layer(x)), p=0.1)\n",
    "        h2 = F.dropout(F.relu(self.enc_h(h1)), p=0.1)\n",
    "        return self.enc_mu(h2), self.enc_sigma(h2)\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h3 = F.dropout(F.relu(self.dec_h(z)), p=0.1)\n",
    "        h4 = F.dropout(F.relu(self.dec_layer(h3)), p=0.1)\n",
    "        temp = torch.sigmoid(self.out_layer(h4))\n",
    "        temp = tdist.ContinuousBernoulli(probs=temp) \n",
    "        return temp.mean\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mu, logvar = self.encode(x.view(-1, self.data_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "class BetaVAE(nn.Module):\n",
    "    def __init__(self, hidden_dims=[500, 500, 20, 500, 500], data_dim=784):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # self.beta_reg = nn.Parameter(torch.ones(1))\n",
    "        # define IO\n",
    "        self.in_layer = nn.Linear(data_dim, hidden_dims[0])\n",
    "        self.out_layer = nn.Linear(hidden_dims[-1], 2*data_dim)\n",
    "        # self.out_layer_alpha = nn.Linear(hidden_dims[-1], data_dim)\n",
    "        # self.out_layer_beta = nn.Linear(hidden_dims[-1], data_dim)\n",
    "        # hidden layer\n",
    "        self.enc_h = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        # define hidden and latent\n",
    "        self.enc_mu = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.enc_sigma = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        # hidden layer decoder\n",
    "        self.dec_h = nn.Linear(hidden_dims[2], hidden_dims[-2])\n",
    "        self.dec_layer = nn.Linear(hidden_dims[-2], hidden_dims[-1])\n",
    "        self.to(device)\n",
    "        \n",
    "    def encode(self, x: torch.Tensor):\n",
    "        h1 = F.dropout(F.relu(self.in_layer(x)), p=0.1)\n",
    "        h2 = F.dropout(F.relu(self.enc_h(h1)), p=0.1)\n",
    "        return self.enc_mu(h2), self.enc_sigma(h2)\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h3 = F.dropout(F.relu(self.dec_h(z)), p=0.1)\n",
    "        h4 = F.dropout(F.relu(self.dec_layer(h3)), p=0.1)\n",
    "        beta_params = self.out_layer(h4)\n",
    "        alphas = 1e-6 + F.softmax(beta_params[:, :self.data_dim])\n",
    "        betas = 1e-6 + F.softmax(beta_params[:, self.data_dim:])\n",
    "        # alphas = 1e-6 + F.relu(beta_params[:, :self.data_dim])\n",
    "        # betas = 1e-6 + F.relu(beta_params[:, self.data_dim:])\n",
    "        return alphas, betas\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mu, logvar = self.encode(x.view(-1, self.data_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        alphas, betas = self.decode(z)\n",
    "        return alphas, betas, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in trained models \n",
    "\n",
    "vae2_model = torch.load(f'{MODEL_PATH}/vae2_100.pt')\n",
    "vae20_model = torch.load(f'{MODEL_PATH}/vae20_100.pt')\n",
    "cbvae_model = torch.load(f'{MODEL_PATH}/cbvae_100.pt')\n",
    "betavae_model = torch.load(f'{MODEL_PATH}/betavae_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47232/1304591353.py:155: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alphas = 1e-6 + F.softmax(beta_params[:, :self.data_dim])\n",
      "/tmp/ipykernel_47232/1304591353.py:156: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  betas = 1e-6 + F.softmax(beta_params[:, self.data_dim:])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        recon_vae2, _, _ = vae2_model(data)\n",
    "        recon_vae20, _, _ = vae20_model(data)\n",
    "        recon_cbvae, _, _ = cbvae_model(data)\n",
    "        alphas, betas, _, _ = betavae_model(data)\n",
    "        recon_betavae = alphas / (alphas + betas)\n",
    "        break\n",
    "\n",
    "n = 16\n",
    "\n",
    "recon_vae2 = recon_vae2.view(128, 1, 28, 28)\n",
    "recon_vae20 = recon_vae20.view(128, 1, 28, 28)\n",
    "recon_cbvae = recon_cbvae.view(128, 1, 28, 28)\n",
    "recon_betavae = recon_betavae.view(128, 1, 28, 28)\n",
    "\n",
    "comparison = torch.cat([data[:n], recon_vae2[:n], recon_vae20[:n], recon_cbvae[:n], recon_betavae[:n]])\n",
    "\n",
    "save_image(comparison.cpu(),\n",
    "                           f'{FIG_PATH}/reconstruction_comparison.png', nrow=n)\n",
    "\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# for i in range(1, 3*n+1):\n",
    "#     ax = plt.subplot(4,n,i)\n",
    "#     plt.imshow(comparison.cpu().detach().numpy()[i-1, 0,:,:], cmap=\"gray\")\n",
    "#     plt.axis('off')\n",
    "\n",
    "# plt.savefig('figs/reconstruction_comparison_b_cb.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47232/1304591353.py:155: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alphas = 1e-6 + F.softmax(beta_params[:, :self.data_dim])\n",
      "/tmp/ipykernel_47232/1304591353.py:156: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  betas = 1e-6 + F.softmax(beta_params[:, self.data_dim:])\n"
     ]
    }
   ],
   "source": [
    "datapoints = []\n",
    "with torch.no_grad():\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        datapoints.append(data[0])\n",
    "        # break\n",
    "\n",
    "repetitions = 16\n",
    "\n",
    "datapoint = datapoints[2]\n",
    "datapoint = datapoint.view(-1, 784)\n",
    "vae_mu, vae_logvar = vae2_model.encode(datapoint)\n",
    "cbvae_mu, cbvae_logvar = cbvae_model.encode(datapoint)\n",
    "betavae_mu, betavae_logvar = betavae_model.encode(datapoint)\n",
    "\n",
    "\n",
    "# generate normal distribution 20 dim samples\n",
    "random_samples2 = tdist.Normal(0, 1).sample((repetitions, 2)).to(device)\n",
    "random_samples20 = tdist.Normal(0, 1).sample((repetitions, 20)).to(device)\n",
    "\n",
    "\n",
    " \n",
    "vae2_recon = vae2_model.decode(random_samples2).view(repetitions, 1, 28, 28)\n",
    "vae20_recon = vae20_model.decode(random_samples20).view(repetitions, 1, 28, 28)\n",
    "cbvae_recon = cbvae_model.decode(random_samples20).view(repetitions, 1, 28, 28)\n",
    "betavae_alphas, betavae_betas = betavae_model.decode(random_samples20)\n",
    "betavae_recon = betavae_alphas / (betavae_alphas + betavae_betas)\n",
    "betavae_recon = betavae_recon.view(repetitions, 1, 28, 28)\n",
    "\n",
    "\n",
    "\n",
    "comparison = torch.cat([vae2_recon[:n], vae20_recon[:n], cbvae_recon[:n], betavae_recon[:n]])\n",
    "\n",
    "save_image(comparison.cpu(),\n",
    "                           f'{FIG_PATH}/sampling_comparison.png', nrow=n)\n",
    "\n",
    "save_image(vae2_recon.view(repetitions, 1, 28, 28), f'{FIG_PATH}/vae2_recon.png')\n",
    "save_image(vae20_recon.view(repetitions, 1, 28, 28), f'{FIG_PATH}/vae20_recon.png')\n",
    "save_image(cbvae_recon.view(repetitions, 1, 28, 28), f'{FIG_PATH}/cbvae_recon.png')\n",
    "save_image(betavae_recon.view(repetitions, 1, 28, 28), f'{FIG_PATH}/betavae_recon.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
